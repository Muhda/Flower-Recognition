{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4323601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libary\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4082474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Data PreProcessing\n",
    "#Training Image processing\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "                'training_set',target_size=(64,64),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fcfd5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Test image processing\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory('test_set',target_size=(64,64),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084a6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Model\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c83c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Convolution Layer\n",
    "#First layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05971267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b499f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a27ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2348bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiddden layer\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86796b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123dd185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For compile results\n",
    "cnn.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a3b0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "135/135 [==============================] - 68s 480ms/step - loss: 1.2927 - accuracy: 0.4556 - val_loss: 1.2972 - val_accuracy: 0.5031\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 32s 239ms/step - loss: 1.0617 - accuracy: 0.5812 - val_loss: 1.0155 - val_accuracy: 0.6041\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 34s 249ms/step - loss: 0.9581 - accuracy: 0.6317 - val_loss: 0.8430 - val_accuracy: 0.6866\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 32s 240ms/step - loss: 0.8829 - accuracy: 0.6632 - val_loss: 0.7517 - val_accuracy: 0.7239\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 32s 240ms/step - loss: 0.8281 - accuracy: 0.6887 - val_loss: 0.7866 - val_accuracy: 0.7005\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 33s 244ms/step - loss: 0.7900 - accuracy: 0.6901 - val_loss: 0.7058 - val_accuracy: 0.7318\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 33s 244ms/step - loss: 0.7530 - accuracy: 0.7067 - val_loss: 0.6449 - val_accuracy: 0.7528\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 32s 237ms/step - loss: 0.7223 - accuracy: 0.7248 - val_loss: 0.5678 - val_accuracy: 0.7890\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 32s 237ms/step - loss: 0.6961 - accuracy: 0.7325 - val_loss: 0.6078 - val_accuracy: 0.7741\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 32s 235ms/step - loss: 0.6775 - accuracy: 0.7401 - val_loss: 0.6002 - val_accuracy: 0.7832\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 31s 233ms/step - loss: 0.6490 - accuracy: 0.7528 - val_loss: 0.5701 - val_accuracy: 0.7846\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 31s 233ms/step - loss: 0.6419 - accuracy: 0.7558 - val_loss: 0.5105 - val_accuracy: 0.8103\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 31s 232ms/step - loss: 0.5997 - accuracy: 0.7746 - val_loss: 0.4798 - val_accuracy: 0.8253\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 32s 235ms/step - loss: 0.5830 - accuracy: 0.7795 - val_loss: 0.5478 - val_accuracy: 0.7920\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 32s 235ms/step - loss: 0.5676 - accuracy: 0.7874 - val_loss: 0.4821 - val_accuracy: 0.8191\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 32s 236ms/step - loss: 0.5472 - accuracy: 0.7978 - val_loss: 0.5464 - val_accuracy: 0.8175\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 32s 238ms/step - loss: 0.5400 - accuracy: 0.7957 - val_loss: 0.4489 - val_accuracy: 0.8355\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 32s 240ms/step - loss: 0.5316 - accuracy: 0.8024 - val_loss: 0.4700 - val_accuracy: 0.8260\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 32s 236ms/step - loss: 0.5098 - accuracy: 0.8084 - val_loss: 0.3307 - val_accuracy: 0.8842\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 33s 243ms/step - loss: 0.5168 - accuracy: 0.8193 - val_loss: 0.3741 - val_accuracy: 0.8633\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 32s 236ms/step - loss: 0.4822 - accuracy: 0.8223 - val_loss: 0.3238 - val_accuracy: 0.8795\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 32s 238ms/step - loss: 0.4824 - accuracy: 0.8214 - val_loss: 0.3788 - val_accuracy: 0.8761\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 32s 237ms/step - loss: 0.4560 - accuracy: 0.8351 - val_loss: 0.3954 - val_accuracy: 0.8555\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 32s 238ms/step - loss: 0.4435 - accuracy: 0.8409 - val_loss: 0.2656 - val_accuracy: 0.9064\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 32s 238ms/step - loss: 0.4442 - accuracy: 0.8365 - val_loss: 0.3229 - val_accuracy: 0.8867\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 32s 236ms/step - loss: 0.4368 - accuracy: 0.8344 - val_loss: 0.3197 - val_accuracy: 0.8867\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 32s 237ms/step - loss: 0.4132 - accuracy: 0.8522 - val_loss: 0.2524 - val_accuracy: 0.9120\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 32s 237ms/step - loss: 0.4053 - accuracy: 0.8494 - val_loss: 0.3258 - val_accuracy: 0.8860\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 32s 237ms/step - loss: 0.4094 - accuracy: 0.8531 - val_loss: 0.2458 - val_accuracy: 0.9187\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 32s 236ms/step - loss: 0.3912 - accuracy: 0.8531 - val_loss: 0.2558 - val_accuracy: 0.9055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b6fc8bca0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set,validation_data=test_set,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d31f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 262ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess New Image\n",
    "from keras.preprocessing import image\n",
    "test_image = tf.keras.utils.load_img('Prediction/wr.jpg',target_size=(64,64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1204b66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daisy\n"
     ]
    }
   ],
   "source": [
    "if result[0][0]==1:\n",
    "    print('Daisy')\n",
    "elif result[0][1]==1:\n",
    "    print('Dandelion')\n",
    "elif result[0][2]==1:\n",
    "    print('Rose')\n",
    "elif result[0][3]==1:\n",
    "    print('SunFlower')\n",
    "elif result[0][4]==1:\n",
    "    print(\"Tulip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e506a07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
